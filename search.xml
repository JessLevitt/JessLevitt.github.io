<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Face Recognition Performance Metrics</title>
      <link href="/2021/08/16/Face%20Recognition%20Performance%20Metrics/"/>
      <url>/2021/08/16/Face%20Recognition%20Performance%20Metrics/</url>
      
        <content type="html"><![CDATA[<h2 id="Background">Background</h2><p>在CV领域中，face recognition是一项非常经典且被广泛应用的技术。本文简单介绍两种不同侧重的face recognition任务，以及可以通过哪些metrics来评估model performance。</p><h2 id="Face-Verification">Face Verification</h2><p>该任务的目的是给定一系列的face image pairs，判断哪些pair是属于同一个人，哪些pair属于不同人。例如，在高铁站入口处，刷过身份证之后系统会调取数据库中的目标face image，人脸闸机则会捕捉当前待验证人的face image。系统再调用face verification model来判断这二者是否是同一个人。</p><p>一般的face verification建模思路是：提取face images的embeddings，根据两个embeddings的某种相似度量以及设定的阈值，来判断两个embeddings对应的face images是否来自同一个人。</p><p>假定testing set包含 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi></mrow><annotation encoding="application/x-tex">M</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span></span></span></span>​​ 个images pairs：</p><ul><li>TP：相似度大于给定阈值且是同一个人的images pairs数量</li><li>FP：相似度大于给定阈值且不是同一个人的images pairs数量</li><li>FN：相似度小于给定阈值且是同一个人的images pairs数量</li><li>TN：相似度小于给定阈值且不是同一个人的images pairs数量</li></ul><p>基于上述定义，可以定义以下metrics：</p><ul><li>accuracy: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi></mrow><annotation encoding="application/x-tex">M</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span></span></span></span> 个images pairs判定正确的image pairs数量</li></ul><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>a</mi><mi>c</mi><mi>c</mi><mo>=</mo><mfrac><mrow><mi>T</mi><mi>P</mi><mo>+</mo><mi>T</mi><mi>N</mi></mrow><mrow><mi>T</mi><mi>P</mi><mo>+</mo><mi>T</mi><mi>N</mi><mo>+</mo><mi>F</mi><mi>P</mi><mo>+</mo><mi>F</mi><mi>N</mi></mrow></mfrac><mo>=</mo><mfrac><mrow><mi>T</mi><mi>P</mi><mo>+</mo><mi>T</mi><mi>N</mi></mrow><mi>M</mi></mfrac></mrow><annotation encoding="application/x-tex">a c c=\frac{T P+T N}{T P+T N+F P+F N}=\frac{T P+T N}{M}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">a</span><span class="mord mathnormal">cc</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.1296600000000003em;vertical-align:-0.7693300000000001em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.36033em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">TP</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">TN</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">FP</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">FN</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">TP</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">TN</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.7693300000000001em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.04633em;vertical-align:-0.686em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.36033em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">M</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">TP</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">TN</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p><ul><li>TAR (True Accept Rate): 属于同一人的image pairs中，相似度大于阈值的image pairs比例。在其他场景中，也叫做recall、TPR (True Positive Rate)、sensitivity</li></ul><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>T</mi><mi>A</mi><mi>R</mi><mo>=</mo><mfrac><mrow><mi>T</mi><mi>P</mi></mrow><mrow><mi>T</mi><mi>P</mi><mo>+</mo><mi>F</mi><mi>N</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">T A R=\frac{T P}{T P+F N}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal">A</span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.1296600000000003em;vertical-align:-0.7693300000000001em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.36033em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">TP</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">FN</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">TP</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.7693300000000001em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p><ul><li>FAR (False Accept Rate): 不属于同一个人的image pairs中，相似度大于阈值的image pairs比例。在其他场景中，也叫做FPR (False Positive Rate)、误报率</li></ul><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>F</mi><mi>A</mi><mi>R</mi><mo>=</mo><mfrac><mrow><mi>F</mi><mi>P</mi></mrow><mrow><mi>F</mi><mi>P</mi><mo>+</mo><mi>T</mi><mi>N</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">F A R=\frac{F P}{F P+T N}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">F</span><span class="mord mathnormal">A</span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.1296600000000003em;vertical-align:-0.7693300000000001em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.36033em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">FP</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">TN</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">FP</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.7693300000000001em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p><ul><li>FRR (False Reject Rate): 属于同一个人的image pairs中，相似度小于阈值的image pairs比例。在其他场景中，也叫做FNR (False Negative Rate)、漏报率</li></ul><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>F</mi><mi>R</mi><mi>R</mi><mo>=</mo><mfrac><mrow><mi>F</mi><mi>N</mi></mrow><mrow><mi>F</mi><mi>N</mi><mo>+</mo><mi>T</mi><mi>P</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">F R R=\frac{F N}{F N+T P}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">FRR</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.1296600000000003em;vertical-align:-0.7693300000000001em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.36033em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">FN</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">TP</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">FN</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.7693300000000001em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p><p>在face verification任务中，我们通常希望保持FAR在一个极小的范围内，然后对比TAR或者FRR，希望TAR越大越好或者FRR越小越好(FRR = 1 - TAR)。因此常用的metrics是accuracy和TAR@FAR</p><p>通常我们会使用另外一个不同源的数据集作为验证集，来计算上述metrics以检验model performance（例如常见的LFW数据集），accuracy的计算步骤如下：</p><ol><li>采用K折交叉验证的思路将所有的验证图像对分为K组，每次选取一组用于确定最佳阈值，剩下的K-1组用于评估</li><li>设置阈值的遍历范围，如以0.1的步长遍历0到1的范围，在某一阈值下，确定单个组上的accuracy</li><li>根据单个组上各阈值下的accuracy确定最佳阈值</li><li>计算最佳阈值下，K-1组上的accuracy</li><li>选取另外K-1组的数据中的某一个用于确定最佳阈值，剩余的用于评估，重复1-4的步得到另外K-1个accuracy</li><li>求K个accuracy的均值和方差作为最终的accuracy</li></ol><p>TAR@FAR的计算方式为：</p><ol><li>采用K折交叉验证的思路将所有的验证图像对分为K组，每次选取一组用于确定最佳阈值，剩下的K-1组用于评估</li><li>设置阈值的遍历范围，如以0.1的步长遍历0到1的范围，测试在每一阈值下，单个组上的TAR和FAR并记录</li><li>重复1-2的步，得到K组各阈值下的TAR和FAR，TAR是一个K行M列的数组，FAR也是同样的，每一行表示每折的结果，每列表示每个阈值下的结果</li><li>对TAR和FAR按axis=0的方向求均值，得到最终的TAR@FAR，可以使用该行向量绘制以FAR为横坐标，TAR为纵坐标的ROC曲线。很多情况下是报告TAR@FAR，例如TAR@FAR=<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><msup><mn>0</mn><mrow><mo>−</mo><mn>6</mn></mrow></msup></mrow><annotation encoding="application/x-tex">10^{-6}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord">1</span><span class="mord"><span class="mord">0</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">6</span></span></span></span></span></span></span></span></span></span></span></span></li></ol><h2 id="Face-Recognition">Face Recognition</h2><p>该任务的目的是给定一张face image(prob)，通过对比底库图像集(gallary)判断该人员的身份信息。根据prob对应的人员是否是gallary内人员，又将face recognition分成了close-set和open-set两种。</p><h3 id="Close-set">Close-set</h3><p>指prob肯定隶属于gallary内的人员，且和已包含在gallary内的图像不同。</p><p>常用的metric是rank-K@gallary：给定prob，同样采用对比embedding similarity的方法，按相似度大小对gallary内图像结果进行排序。前K个结果中包含了prob对应人员的比例。常用的K值有1，5，10，100等，当然K值要小于等于底库规模，当K值等于底库规模时，则rank-K等于1。K值越大，rank-K的值也越大。因此可以以K值为横轴，rank-K值为纵轴，绘制CMC曲线。</p><h3 id="Open-set">Open-set</h3><p>指prob不一定隶属于gallary内的人员。常用的metrics有rank-K@FAR和TAR@FAR。</p><p>对于open-set，测试结果有五种情况：</p><ul><li>prob属于gallary内人员，相似度大于阈值，识别结果正确，这样的样本个数记为 IBC (in &amp; bigger &amp; correct)</li><li>prob属于gallary内人员，相似度大于阈值，识别结果错误，这样的样本个数记为 IBE (in &amp; bigger &amp; error)</li><li>prob属于gallary内人员，相似度小于阈值，这样的样本个数记为 IS (in &amp; smaller)</li><li>prob不属于gallary内人员，相似度大于阈值，这样的样本个数记为 OB (out &amp; bigger)</li><li>prob不属于gallary内人员，相似度小于阈值，这样的样本个数记为 OS (out &amp; smaller)</li></ul><h4 id="Rank-k-FAR">Rank-k@FAR</h4><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.2500em" columnalign="center" columnspacing="0em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mi>R</mi><mi>a</mi><mi>n</mi><mi>k</mi><mn>1</mn><mo>=</mo><mfrac><mrow><mi>I</mi><mi>B</mi><mi>C</mi></mrow><mtext>测试集中库内人员数量</mtext></mfrac></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mi>R</mi><mi>a</mi><mi>n</mi><mi>k</mi><mi>K</mi><mo>=</mo><mfrac><mrow><mtext>前</mtext><mi>K</mi><mtext>个结果包含真正人员的</mtext><mi>I</mi><mi>B</mi><mi>C</mi></mrow><mtext>测试集中库内人员数量</mtext></mfrac></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mi>F</mi><mi>A</mi><mi>R</mi><mo>=</mo><mfrac><mrow><mi>O</mi><mi>B</mi></mrow><mtext>测试集中库外人员数量</mtext></mfrac></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{gathered}Rank1=\frac{IBC}{测试集中库内人员数量} \\RankK=\frac{前K个结果包含真正人员的IBC}{测试集中库内人员数量} \\FAR=\frac{OB}{测试集中库外人员数量}\end{gathered}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:7.03899em;vertical-align:-3.2694950000000005em;"></span><span class="mord"><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:3.7694949999999996em;"><span style="top:-5.769495em;"><span class="pstrut" style="height:3.3603300000000003em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord mathnormal" style="margin-right:0.03148em;">ank</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.36033em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord cjk_fallback">测试集中库内人员数量</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="mord mathnormal" style="margin-right:0.07153em;">BC</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span><span style="top:-3.423165em;"><span class="pstrut" style="height:3.3603300000000003em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord mathnormal" style="margin-right:0.03148em;">ank</span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.36033em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord cjk_fallback">测试集中库内人员数量</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord cjk_fallback">前</span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mord cjk_fallback">个结果包含真正人员的</span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="mord mathnormal" style="margin-right:0.07153em;">BC</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span><span style="top:-1.076835em;"><span class="pstrut" style="height:3.3603300000000003em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">F</span><span class="mord mathnormal">A</span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.36033em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord cjk_fallback">测试集中库外人员数量</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">OB</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:3.2694950000000005em;"><span></span></span></span></span></span></span></span></span></span></span></span></p><p>通常希望保持FAR在一个极小的范围内。根据FAR的取值确定阈值，报告各阈值下的Rank-K值。</p><h4 id="TAR-FAR">TAR@FAR</h4><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.2500em" columnalign="right left" columnspacing="0em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mi>T</mi><mi>A</mi><mi>R</mi><mo>=</mo><mfrac><mrow><mi>I</mi><mi>B</mi><mi>C</mi></mrow><mtext>测试集中库内人员数量</mtext></mfrac></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mi>F</mi><mi>A</mi><mi>R</mi><mo>=</mo><mfrac><mrow><mi>O</mi><mi>B</mi></mrow><mtext>测试集中库外人员数量</mtext></mfrac></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{aligned}&amp;TAR=\frac{IBC}{测试集中库内人员数量} \\&amp;FAR=\frac{OB}{测试集中库外人员数量}\end{aligned}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:4.69266em;vertical-align:-2.09633em;"></span><span class="mord"><span class="mtable"><span class="col-align-r"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.59633em;"><span style="top:-4.59633em;"><span class="pstrut" style="height:3.3603300000000003em;"></span><span class="mord"></span></span><span style="top:-2.2500000000000004em;"><span class="pstrut" style="height:3.3603300000000003em;"></span><span class="mord"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.09633em;"><span></span></span></span></span></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.59633em;"><span style="top:-4.59633em;"><span class="pstrut" style="height:3.3603300000000003em;"></span><span class="mord"><span class="mord"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal">A</span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.36033em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord cjk_fallback">测试集中库内人员数量</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="mord mathnormal" style="margin-right:0.07153em;">BC</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span><span style="top:-2.2500000000000004em;"><span class="pstrut" style="height:3.3603300000000003em;"></span><span class="mord"><span class="mord"></span><span class="mord mathnormal" style="margin-right:0.13889em;">F</span><span class="mord mathnormal">A</span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.36033em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord cjk_fallback">测试集中库外人员数量</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">OB</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.09633em;"><span></span></span></span></span></span></span></span></span></span></span></span></p><p>同样根据FAR的取值确定阈值，报告各阈值下的TAR值，FAR依据测试集中库外人员的数量一般取<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><msup><mn>0</mn><mrow><mo>−</mo><mn>6</mn></mrow></msup></mrow><annotation encoding="application/x-tex">10^{-6}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord">1</span><span class="mord"><span class="mord">0</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">6</span></span></span></span></span></span></span></span></span></span></span></span>。​</p><h4 id="FRR-FAR">FRR@FAR</h4><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.2500em" columnalign="right left" columnspacing="0em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mi>F</mi><mi>R</mi><mi>R</mi><mo>=</mo><mfrac><mrow><mi>I</mi><mi>S</mi></mrow><mtext>测试集中库内人员数量</mtext></mfrac></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mi>F</mi><mi>A</mi><mi>R</mi><mo>=</mo><mfrac><mrow><mi>O</mi><mi>B</mi></mrow><mtext>测试集中库外人员数量</mtext></mfrac></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{aligned}&amp;FRR=\frac{IS}{测试集中库内人员数量}\\&amp;FAR=\frac{OB}{测试集中库外人员数量}\end{aligned}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:4.69266em;vertical-align:-2.09633em;"></span><span class="mord"><span class="mtable"><span class="col-align-r"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.59633em;"><span style="top:-4.59633em;"><span class="pstrut" style="height:3.3603300000000003em;"></span><span class="mord"></span></span><span style="top:-2.2500000000000004em;"><span class="pstrut" style="height:3.3603300000000003em;"></span><span class="mord"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.09633em;"><span></span></span></span></span></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.59633em;"><span style="top:-4.59633em;"><span class="pstrut" style="height:3.3603300000000003em;"></span><span class="mord"><span class="mord"></span><span class="mord mathnormal" style="margin-right:0.00773em;">FRR</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.36033em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord cjk_fallback">测试集中库内人员数量</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span><span style="top:-2.2500000000000004em;"><span class="pstrut" style="height:3.3603300000000003em;"></span><span class="mord"><span class="mord"></span><span class="mord mathnormal" style="margin-right:0.13889em;">F</span><span class="mord mathnormal">A</span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.36033em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord cjk_fallback">测试集中库外人员数量</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">OB</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.09633em;"><span></span></span></span></span></span></span></span></span></span></span></span></p><p>同样根据FAR的取值确定阈值，报告各阈值下的FRR值，FAR依据测试集中库外人员的数量一般取<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><msup><mn>0</mn><mrow><mo>−</mo><mn>6</mn></mrow></msup></mrow><annotation encoding="application/x-tex">10^{-6}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord">1</span><span class="mord"><span class="mord">0</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">6</span></span></span></span></span></span></span></span></span></span></span></span>。​</p>]]></content>
      
      
      <categories>
          
          <category> Deep Learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Metric Learning </tag>
            
            <tag> Metrics </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Triplet Loss and Online Triplet Mining</title>
      <link href="/2021/08/14/Triplet%20Loss%20and%20Online%20Triplet%20Mining/"/>
      <url>/2021/08/14/Triplet%20Loss%20and%20Online%20Triplet%20Mining/</url>
      
        <content type="html"><![CDATA[<h2 id="Background">Background</h2><p>在论文<a href="https://arxiv.org/abs/1503.03832">FaceNet: A Unified Embedding for Face Recognition and Clustering</a>中，triplet loss被首次提出并用于来学习人脸embedding。</p><p>在一般的classification task中，样本的类别数是事先固定的，我们可以使用softmax corss entropy loss训练network。然而，在某些情况下类别数是一个变量。以face recognition为例，我们需要对比两张face image来判断他们是否是同一个人，然而其中任意一张image都可能未在training set中出现。因而，我们希望能够训练这样一个network：在其对应的embedding space中，同类样本紧密相邻，异类样本形成分离良好的簇。</p><h2 id="Definition-of-Triplet-Loss">Definition of Triplet Loss</h2><p><img src="https://cdn.jsdelivr.net/gh/JessLevitt/CDN/manifest/blog/20210814151303.png" alt=""></p><p>Triplet loss的思想十分简单，它希望在embedding space中：</p><ul><li>同类的两个样本对应的embeddings尽可能地相近</li><li>异类的两个样本对应的embeddings尽可能地远离</li></ul><p>但是，我们其实并不“强求”同类所有样本的embedding都collapse到一个非常小的簇中。而只是希望给定两个同类样本(positive examples)和一个异类样本(negative example)，negative example到最近的positive example的距离要大于一个margin，这一思想和SVM十分类似。</p><p>正式地，triplet loss定义在一个embedding triplet上：</p><ul><li>一个anchor</li><li>一个positive(与anchor同类)</li><li>一个negative(与anchor异类)</li></ul><p>对于某种在embedding space上距离度量方法 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi></mrow><annotation encoding="application/x-tex">d</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">d</span></span></span></span>，在<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>a</mi><mo separator="true">,</mo><mi>p</mi><mo separator="true">,</mo><mi>n</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(a,p,n)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal">a</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">p</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">n</span><span class="mclose">)</span></span></span></span>上的triplet loss定义为：</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi mathvariant="script">L</mi><mo>=</mo><mi>max</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi>d</mi><mo stretchy="false">(</mo><mi>a</mi><mo separator="true">,</mo><mi>p</mi><mo stretchy="false">)</mo><mo>−</mo><mi>d</mi><mo stretchy="false">(</mo><mi>a</mi><mo separator="true">,</mo><mi>n</mi><mo stretchy="false">)</mo><mo>+</mo><mi mathvariant="normal">margin</mi><mo>⁡</mo><mo separator="true">,</mo><mn>0</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\mathcal{L}=\max (d(a, p)-d(a, n)+\operatorname{margin}, 0)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathcal">L</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop">max</span><span class="mopen">(</span><span class="mord mathnormal">d</span><span class="mopen">(</span><span class="mord mathnormal">a</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">p</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">d</span><span class="mopen">(</span><span class="mord mathnormal">a</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">n</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop"><span class="mord mathrm">margin</span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">0</span><span class="mclose">)</span></span></span></span></span></p><p>我们通过最小化triplet loss来使得 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi><mo stretchy="false">(</mo><mi>a</mi><mo separator="true">,</mo><mi>n</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">d(a,n)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">d</span><span class="mopen">(</span><span class="mord mathnormal">a</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">n</span><span class="mclose">)</span></span></span></span> ​大于 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi><mo stretchy="false">(</mo><mi>a</mi><mo separator="true">,</mo><mi>p</mi><mo stretchy="false">)</mo><mo>+</mo><mi>m</mi><mi>a</mi><mi>r</mi><mi>g</mi><mi>i</mi><mi>n</mi></mrow><annotation encoding="application/x-tex">d(a,p) + margin</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">d</span><span class="mopen">(</span><span class="mord mathnormal">a</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">p</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.85396em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">ma</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord mathnormal">in</span></span></span></span>​​。</p><h2 id="Triplet-Mining">Triplet Mining</h2><p>基于triplet loss的定义，会出现三种不同类型的triplets:</p><ul><li>easy triplets: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi><mo stretchy="false">(</mo><mi>a</mi><mo separator="true">,</mo><mi>p</mi><mo stretchy="false">)</mo><mo>+</mo><mi>m</mi><mi>a</mi><mi>r</mi><mi>g</mi><mi>i</mi><mi>n</mi><mo>&lt;</mo><mi>d</mi><mo stretchy="false">(</mo><mi>a</mi><mo separator="true">,</mo><mi>n</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">d(a,p) + margin &lt; d(a,n)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">d</span><span class="mopen">(</span><span class="mord mathnormal">a</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">p</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.85396em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">ma</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord mathnormal">in</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">d</span><span class="mopen">(</span><span class="mord mathnormal">a</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">n</span><span class="mclose">)</span></span></span></span>，此时triplet loss为零</li><li>hard triplets: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi><mo stretchy="false">(</mo><mi>a</mi><mo separator="true">,</mo><mi>n</mi><mo stretchy="false">)</mo><mo>&lt;</mo><mi>d</mi><mo stretchy="false">(</mo><mi>a</mi><mo separator="true">,</mo><mi>p</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">d(a,n)&lt;d(a,p)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">d</span><span class="mopen">(</span><span class="mord mathnormal">a</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">n</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">d</span><span class="mopen">(</span><span class="mord mathnormal">a</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">p</span><span class="mclose">)</span></span></span></span>​​，此时negative比positive更靠近anchor</li><li>semi-hard triplets: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi><mo stretchy="false">(</mo><mi>a</mi><mo separator="true">,</mo><mi>p</mi><mo stretchy="false">)</mo><mo>&lt;</mo><mi>d</mi><mo stretchy="false">(</mo><mi>a</mi><mo separator="true">,</mo><mi>n</mi><mo stretchy="false">)</mo><mo>&lt;</mo><mi>d</mi><mo stretchy="false">(</mo><mi>a</mi><mo separator="true">,</mo><mi>p</mi><mo stretchy="false">)</mo><mo>+</mo><mi>m</mi><mi>a</mi><mi>r</mi><mi>g</mi><mi>i</mi><mi>n</mi></mrow><annotation encoding="application/x-tex">d(a, p)&lt;d(a, n)&lt;d(a, p)+ margin</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">d</span><span class="mopen">(</span><span class="mord mathnormal">a</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">p</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">d</span><span class="mopen">(</span><span class="mord mathnormal">a</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">n</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">d</span><span class="mopen">(</span><span class="mord mathnormal">a</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">p</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.85396em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">ma</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord mathnormal">in</span></span></span></span>，此时positive更靠近anchor，但是negative与positive的距离小于margin</li></ul><p><img src="https://cdn.jsdelivr.net/gh/JessLevitt/CDN/manifest/blog/20210814144658.png" alt=""></p><p>选择不同的triplets训练会很大程度地影响最终network的generalization performance。在Facenet论文中，给定anchor和positive，作者随机选择一个semi-hard negative组成triplet训练network。</p><h3 id="Offline-and-Online-Triplet-Mining">Offline and Online Triplet Mining</h3><p>我们已经定义了triplet loss以及不同种类的triplets，接下来的问题就是如果mining这些用于训练的triplets。</p><h4 id="Offline-Triplet-Mining">Offline Triplet Mining</h4><p>在每个training epoch开始之前，计算整个training set的embeddings，然后根据策略选择hard triplets或者semi-hard triplets，然后只在这些triplets上训练network。这种方式显然是非常低效的。</p><h4 id="Online-Triplet-Mining">Online Triplet Mining</h4><p>在Facenet论文中使用的是online triplet mining方法：对于每个batch data，动态地生成用于训练的triplets。假设一个batch包含了 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span> 个样本，那么我们最多可以找到 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>B</mi><mn>3</mn></msup></mrow><annotation encoding="application/x-tex">B^3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span></span></span></span></span></span></span></span>​ 个triplets。当然其中很多triplets都是invalid的(不满足两个positives和一个negative)。online triplet mining可以高效地识别出valid triplets。</p><h2 id="Strategies-in-Online-Mining">Strategies in Online Mining</h2><p>在online triplet mining中，我们首先计算 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span>​ 个样本的embedding，然后再生成valid triplets。假设挑选的三个样本对应的索引为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi><mo separator="true">,</mo><mi>j</mi><mo separator="true">,</mo><mi>k</mi></mrow><annotation encoding="application/x-tex">i,j,k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">i</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.05724em;">j</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span>。那么当 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.65952em;vertical-align:0em;"></span><span class="mord mathnormal">i</span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>j</mi></mrow><annotation encoding="application/x-tex">j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.85396em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.05724em;">j</span></span></span></span> 属于同类，而 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span> 是异类时，这样的triplet是valid。</p><p>假设一个batch中的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span> 个样本，对应 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi></mrow><annotation encoding="application/x-tex">P</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span></span></span></span> 不同的人，每个人有 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span></span></span></span>​ 张face images。那么，可以有两种不同的mining strategies:</p><ul><li>batch all: 识别所有的valid triplets，仅计算在hard triplets和semi-hard triplets上的average loss。<ul><li>关键点在于不将easy triplets的loss计算在内，否则average loss会非常小</li><li>valid triplets的数量是：<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mi>K</mi><mo stretchy="false">(</mo><mi>K</mi><mo>−</mo><mn>1</mn><mo stretchy="false">)</mo><mo stretchy="false">(</mo><mi>P</mi><mi>K</mi><mo>−</mo><mi>K</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">P K(K-1)(P K-K)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">1</span><span class="mclose">)</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mclose">)</span></span></span></span></li></ul></li><li>batch hard: 对于每一个anchor，选择hardest positive(具有最大的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi><mo stretchy="false">(</mo><mi>a</mi><mo separator="true">,</mo><mi>p</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">d(a,p)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">d</span><span class="mopen">(</span><span class="mord mathnormal">a</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">p</span><span class="mclose">)</span></span></span></span>​)和hardest negatvie(具有最小的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi><mo stretchy="false">(</mo><mi>a</mi><mo separator="true">,</mo><mi>n</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">d(a,n)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">d</span><span class="mopen">(</span><span class="mord mathnormal">a</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">n</span><span class="mclose">)</span></span></span></span>)。<ul><li>triplets的数量是：<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mi>K</mi></mrow><annotation encoding="application/x-tex">PK</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span></span></span></span></li></ul></li></ul><p>根据<a href="https://arxiv.org/abs/1703.07737">paper</a>实验结果，采用batch hard strategy通常可以产生更好的generalization performance。</p><h2 id="Online-Triplet-Mining-Implementation-in-Tensorflow">Online Triplet Mining Implementation in Tensorflow</h2><h3 id="Compute-the-distance-matrix">Compute the distance matrix</h3><p>由于triplet的选择最终取决于 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi><mo stretchy="false">(</mo><mi>a</mi><mo separator="true">,</mo><mi>p</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">d(a,p)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">d</span><span class="mopen">(</span><span class="mord mathnormal">a</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">p</span><span class="mclose">)</span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi><mo stretchy="false">(</mo><mi>a</mi><mo separator="true">,</mo><mi>n</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">d(a,n)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">d</span><span class="mopen">(</span><span class="mord mathnormal">a</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">n</span><span class="mclose">)</span></span></span></span>，因此我们可以先计算一个batch内样本两两之间的距离：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_pairwise_distances</span>(<span class="params">embeddings, squared=<span class="literal">False</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Compute the 2D matrix of distances between all the embeddings.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        embeddings: tensor of shape (batch_size, embed_dim)</span></span><br><span class="line"><span class="string">        squared: Boolean. If true, output is the pairwise squared euclidean distance matrix.</span></span><br><span class="line"><span class="string">                 If false, output is the pairwise euclidean distance matrix.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        pairwise_distances: tensor of shape (batch_size, batch_size)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># Get the dot product between all embeddings</span></span><br><span class="line">    <span class="comment"># shape (batch_size, batch_size)</span></span><br><span class="line">    dot_product = tf.matmul(embeddings, tf.transpose(embeddings))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Get squared L2 norm for each embedding. We can just take the diagonal of `dot_product`.</span></span><br><span class="line">    <span class="comment"># This also provides more numerical stability (the diagonal of the result will be exactly 0).</span></span><br><span class="line">    <span class="comment"># shape (batch_size,)</span></span><br><span class="line">    square_norm = tf.diag_part(dot_product)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Compute the pairwise distance matrix as we have:</span></span><br><span class="line">    <span class="comment"># ||a - b||^2 = ||a||^2  - 2 &lt;a, b&gt; + ||b||^2</span></span><br><span class="line">    <span class="comment"># shape (batch_size, batch_size)</span></span><br><span class="line">    distances = tf.expand_dims(square_norm, <span class="number">0</span>) - <span class="number">2.0</span> * dot_product + tf.expand_dims(square_norm, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Because of computation errors, some distances might be negative so we put everything &gt;= 0.0</span></span><br><span class="line">    distances = tf.maximum(distances, <span class="number">0.0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> squared:</span><br><span class="line">        <span class="comment"># Because the gradient of sqrt is infinite when distances == 0.0 (ex: on the diagonal)</span></span><br><span class="line">        <span class="comment"># we need to add a small epsilon where distances == 0.0</span></span><br><span class="line">        mask = tf.to_float(tf.equal(distances, <span class="number">0.0</span>))</span><br><span class="line">        distances = distances + mask * <span class="number">1e-16</span></span><br><span class="line"></span><br><span class="line">        distances = tf.sqrt(distances)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Correct the epsilon added: set the distances on the mask to be exactly 0.0</span></span><br><span class="line">        distances = distances * (<span class="number">1.0</span> - mask)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> distances</span><br></pre></td></tr></table></figure><h3 id="Batch-all-strategy">Batch all strategy</h3><p>首先计算所有可能的triplets (总共 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>B</mi><mn>3</mn></msup></mrow><annotation encoding="application/x-tex">B^3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span></span></span></span></span></span></span></span> 个)，然后选择确定valid triplets，最后计算triplet loss并仅在hard triplets和semi-hard triplets上计算average loss：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">batch_all_triplet_loss</span>(<span class="params">labels, embeddings, margin, squared=<span class="literal">False</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Build the triplet loss over a batch of embeddings.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    We generate all the valid triplets and average the loss over the positive ones.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        labels: labels of the batch, of size (batch_size,)</span></span><br><span class="line"><span class="string">        embeddings: tensor of shape (batch_size, embed_dim)</span></span><br><span class="line"><span class="string">        margin: margin for triplet loss</span></span><br><span class="line"><span class="string">        squared: Boolean. If true, output is the pairwise squared euclidean distance matrix.</span></span><br><span class="line"><span class="string">                 If false, output is the pairwise euclidean distance matrix.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        triplet_loss: scalar tensor containing the triplet loss</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># Get the pairwise distance matrix</span></span><br><span class="line">    pairwise_dist = _pairwise_distances(embeddings, squared=squared)</span><br><span class="line"></span><br><span class="line">    anchor_positive_dist = tf.expand_dims(pairwise_dist, <span class="number">2</span>)</span><br><span class="line">    anchor_negative_dist = tf.expand_dims(pairwise_dist, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Compute a 3D tensor of size (batch_size, batch_size, batch_size)</span></span><br><span class="line">    <span class="comment"># triplet_loss[i, j, k] will contain the triplet loss of anchor=i, positive=j, negative=k</span></span><br><span class="line">    <span class="comment"># Uses broadcasting where the 1st argument has shape (batch_size, batch_size, 1)</span></span><br><span class="line">    <span class="comment"># and the 2nd (batch_size, 1, batch_size)</span></span><br><span class="line">    triplet_loss = anchor_positive_dist - anchor_negative_dist + margin</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Put to zero the invalid triplets</span></span><br><span class="line">    <span class="comment"># (where label(a) != label(p) or label(n) == label(a) or a == p)</span></span><br><span class="line">    mask = _get_triplet_mask(labels)</span><br><span class="line">    mask = tf.to_float(mask)</span><br><span class="line">    triplet_loss = tf.multiply(mask, triplet_loss)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Remove negative losses (i.e. the easy triplets)</span></span><br><span class="line">    triplet_loss = tf.maximum(triplet_loss, <span class="number">0.0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Count number of positive triplets (where triplet_loss &gt; 0)</span></span><br><span class="line">    valid_triplets = tf.to_float(tf.greater(triplet_loss, <span class="number">1e-16</span>))</span><br><span class="line">    num_positive_triplets = tf.reduce_sum(valid_triplets)</span><br><span class="line">    num_valid_triplets = tf.reduce_sum(mask)</span><br><span class="line">    fraction_positive_triplets = num_positive_triplets / (num_valid_triplets + <span class="number">1e-16</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Get final mean triplet loss over the positive valid triplets</span></span><br><span class="line">    triplet_loss = tf.reduce_sum(triplet_loss) / (num_positive_triplets + <span class="number">1e-16</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> triplet_loss, fraction_positive_triplets</span><br></pre></td></tr></table></figure><h3 id="Batch-hard-strategy">Batch hard strategy</h3><p>为了计算hardest positive，我们首先计算valid mask(<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi><mo mathvariant="normal">≠</mo><mi>q</mi></mrow><annotation encoding="application/x-tex">a \neq q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">a</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel"><span class="mrel"><span class="mord vbox"><span class="thinbox"><span class="rlap"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="inner"><span class="mord"><span class="mrel"></span></span></span><span class="fix"></span></span></span></span></span><span class="mrel">=</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span></span></span></span> 但是<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi></mrow><annotation encoding="application/x-tex">a</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">a</span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">p</span></span></span></span> 是同类)，然后每个row中最大距离所对应的pair就是hardest positive。</p><p>为了计算hardest negative，我们需要找到每个row中的最小距离，因此在计算valid mask是不能将invalid mask设置为0，相反应该设置一个非常大的数。</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">batch_hard_triplet_loss</span>(<span class="params">labels, embeddings, margin, squared=<span class="literal">False</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Build the triplet loss over a batch of embeddings.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    For each anchor, we get the hardest positive and hardest negative to form a triplet.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        labels: labels of the batch, of size (batch_size,)</span></span><br><span class="line"><span class="string">        embeddings: tensor of shape (batch_size, embed_dim)</span></span><br><span class="line"><span class="string">        margin: margin for triplet loss</span></span><br><span class="line"><span class="string">        squared: Boolean. If true, output is the pairwise squared euclidean distance matrix.</span></span><br><span class="line"><span class="string">                 If false, output is the pairwise euclidean distance matrix.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        triplet_loss: scalar tensor containing the triplet loss</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># Get the pairwise distance matrix</span></span><br><span class="line">    pairwise_dist = _pairwise_distances(embeddings, squared=squared)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># For each anchor, get the hardest positive</span></span><br><span class="line">    <span class="comment"># First, we need to get a mask for every valid positive (they should have same label)</span></span><br><span class="line">    mask_anchor_positive = _get_anchor_positive_triplet_mask(labels)</span><br><span class="line">    mask_anchor_positive = tf.to_float(mask_anchor_positive)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># We put to 0 any element where (a, p) is not valid (valid if a != p and label(a) == label(p))</span></span><br><span class="line">    anchor_positive_dist = tf.multiply(mask_anchor_positive, pairwise_dist)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># shape (batch_size, 1)</span></span><br><span class="line">    hardest_positive_dist = tf.reduce_max(anchor_positive_dist, axis=<span class="number">1</span>, keepdims=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># For each anchor, get the hardest negative</span></span><br><span class="line">    <span class="comment"># First, we need to get a mask for every valid negative (they should have different labels)</span></span><br><span class="line">    mask_anchor_negative = _get_anchor_negative_triplet_mask(labels)</span><br><span class="line">    mask_anchor_negative = tf.to_float(mask_anchor_negative)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># We add the maximum value in each row to the invalid negatives (label(a) == label(n))</span></span><br><span class="line">    max_anchor_negative_dist = tf.reduce_max(pairwise_dist, axis=<span class="number">1</span>, keepdims=<span class="literal">True</span>)</span><br><span class="line">    anchor_negative_dist = pairwise_dist + max_anchor_negative_dist * (<span class="number">1.0</span> - mask_anchor_negative)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># shape (batch_size,)</span></span><br><span class="line">    hardest_negative_dist = tf.reduce_min(anchor_negative_dist, axis=<span class="number">1</span>, keepdims=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Combine biggest d(a, p) and smallest d(a, n) into final triplet loss</span></span><br><span class="line">    triplet_loss = tf.maximum(hardest_positive_dist - hardest_negative_dist + margin, <span class="number">0.0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Get final mean triplet loss</span></span><br><span class="line">    triplet_loss = tf.reduce_mean(triplet_loss)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> triplet_loss</span><br></pre></td></tr></table></figure><h2 id="References">References</h2><ul><li><a href="https://omoindrot.github.io/triplet-loss">Triplet Loss and Online Triplet Mining in TensorFlow</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Deep Learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Loss Function </tag>
            
            <tag> Metric Learning </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
